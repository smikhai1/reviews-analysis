import json
import re

import collections
from collections import Counter

import scipy
from scipy import sparse
from scipy.sparse import linalg

import numpy as np

def clear_sentences(data):
    """
        Cleaning sentences, removing special characters and articles
    """
    sentences = list()
    for record in data:
        sentence = record['reviewText']
        sentence = sentence.lower()
        for char in "?.!/;:,":
            sentence = sentence.replace(char, '')

        sentence = sentence.split(sep=' ')
        sentence = [word for word in sentence if len(word) > 1]
        sentences.append(sentence)
        
    return sentences

def create_vocabulary(sentences, r=200):
    vocabulary = dict()
    word_count = dict()
    num = 0
    
    for sentence in sentences:
        for word in sentence:
            if word not in word_count:
                word_count[word] = 1
            else:
                word_count[word] += 1
    
    for word, count in word_count.items():
        if word_count[word] >= r:
            vocabulary[word] = num
            num += 1
    
    return vocabulary

def create_matrix_D(data, vocab, window_size=5):
    """
    Create a co-occurrence matrix D from training corpus.
    """

    dim = len(vocab)
    D = np.zeros((dim, dim))
    s = window_size // 2
            
    for sentence in data:
        l = len(sentence)
        for i in range(l):
            for j in range(max(0,i - s), min(i + s + 1,l)):
                if (i != j and sentence[i] in vocab 
                    and sentence[j] in vocab):
                    c = vocab[sentence[j]]
                    w = vocab[sentence[i]]
                    D[c][w] += 1                  
    return D        


def create_matrix_B(D, k):
    """
    Create matrix B (defined in init).
    """
        
    c_ = D.sum(axis=1)
    w_ = D.sum(axis=0)
    P = D.sum()

    w_v, c_v = np.meshgrid(w_, c_)
    B = k * (w_v * c_v)/float(P)
    return B

def sigmoid(X):
    """
    Sigmoid function sigma(x)=1/(1+e^{-x}) of matrix X.
    """
    Y = X.copy()
        
    Y[X>20] = 1-1e-6
    Y[X<-20] = 1e-6
    Y[(X<20)&(X>-20)] = 1 / (1 + np.exp(-X[(X<20)&(X>-20)]))
        
    return Y

def MF(D, B, X):
    """
    Objective MF(D,C^TW) we want to minimize.
    """
    
    MF = D * np.log(sigmoid(X)) + B * np.log(sigmoid(-X))
    return MF, -MF.mean()


def grad_MF(X, D, B):
    """
    Gradient of the functional MF(D,C^TW) over C^TW.
    """
    
    grad = D * sigmoid(-X) - B * sigmoid(X)
    return grad

class Word2VecController:
    """
    
    """
    
    def compute_embeddings(corpus_matrix=None, vocabulary=None, embedding_computer=None):
        """
            @param corpus_matrix - [w_i, c_i], as it was in second PS, 
                                    generated by create_corpus_matrix (maybe it will be 
                                    generated by another function with similar prototype)
            @param vocabulary - it is obvious, what is it
            @param embedding_computer - function, which return embedding matrix
        """
        
        # preparation and execution embeggin_computer function
        # embedding matrix
        
        # self.embedding = ...
        
        return self
    
    def calc_cosine_similarity(word):
        """
            Cosine similarity calculator (maybe from sklearn)
        """
        
        # calculation similarity
        # similarity = cosine(word, self.embedding)
        
        return similarity
    
class Doc2VecController:
    """
    
    """
    
    def create_document_embedding_matrix(word2vec_controller, data, **kwargs):
        """
            Create matrix with obervations for sklearn._predictor
            @param word2vec_controller -
            @param data - clear data with feedback and grades for constructing doc2vec matrix
            @kwargs - any other params for model
        """
        
        # obsevations - matrix 2d np.ndarray (n, m + 1,) n - words count, m - contexts count, and grade of feedback
        
        return obervations