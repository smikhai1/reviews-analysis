{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_prepaired = '../dataset/dataset.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = None\n",
    "with open(path_data_prepaired) as file_data:\n",
    "    data = json.load(file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import clear_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.43 s, sys: 329 ms, total: 4.76 s\n",
      "Wall time: 4.76 s\n"
     ]
    }
   ],
   "source": [
    "%time sentences = clear_sentences(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(sentences)\n",
    "sentences = sentences[:l//10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Words Embeddings as Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vocabulary\n",
      "Creating corpus matrix\n",
      "Computing of words embeddings\n",
      "-6865082.855317236\n"
     ]
    }
   ],
   "source": [
    "model.create_vocabulary()\n",
    "model.create_corpus_matrix()\n",
    "model.compute_embedds_EMF(5, alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 has started\n",
      "-6865082.855317236\n",
      "Iteration 2 has started\n",
      "-7736484.404539731\n",
      "Iteration 3 has started\n",
      "-6858655.357490511\n",
      "Iteration 4 has started\n",
      "-7726351.684199596\n",
      "Iteration 5 has started\n",
      "-6852173.369949247\n",
      "Iteration 6 has started\n",
      "-7715350.44717634\n",
      "Iteration 7 has started\n",
      "-6844416.531853705\n",
      "Iteration 8 has started\n",
      "-7700483.011641293\n",
      "Iteration 9 has started\n",
      "-6831350.247145227\n",
      "Iteration 10 has started\n",
      "-7671791.640724014\n",
      "Iteration 11 has started\n",
      "-6807374.005320498\n",
      "Iteration 12 has started\n",
      "-7614856.671224229\n",
      "Iteration 13 has started\n",
      "-6824250.237148488\n",
      "Iteration 14 has started\n",
      "-7585577.644440516\n",
      "Iteration 15 has started\n",
      "-7001465.1020168485\n",
      "Iteration 16 has started\n",
      "-7439205.264657776\n",
      "Iteration 17 has started\n",
      "-7148220.860857635\n",
      "Iteration 18 has started\n",
      "-7344992.325126817\n",
      "Iteration 19 has started\n",
      "-7204635.770387191\n",
      "Iteration 20 has started\n",
      "-7513962.833973066\n"
     ]
    }
   ],
   "source": [
    "model.compute_embedds_riem(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model.W @ model.C\n",
    "\n",
    "wc = model.D.sum()\n",
    "w = np.array(model.D.sum(axis=1))\n",
    "c = np.array(model.D.sum(axis=0))\n",
    "\n",
    "model.grad(X, 1, wc, w, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr = np.array(model.D.toarray()) * sigmoid(- X) - (1 * w * c / wc) * sigmoid(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Compute review embeddings #####\n",
    "def get_review_embedding(model, review):\n",
    "    \"\"\"\n",
    "    model -- word2vec model instance, which is used\n",
    "    review -- current review to be embedded\n",
    "    \"\"\"\n",
    "    \n",
    "    review_vec = np.zeros(model.d)\n",
    "    words_count = 0\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    for word in review:\n",
    "        if (word in model.vocab) and not (word in stops):\n",
    "            review_vec += model.get_word_embedding(word)\n",
    "            words_count += 1\n",
    "    review_vec /= words_count\n",
    "    return review_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Compute review embeddings #####\n",
    "def get_features_matrix(model, reviews):\n",
    "    \"\"\"\n",
    "    model -- word2vec model instance, which is used\n",
    "    reviews -- the whole collection of reviews\n",
    "    \"\"\"\n",
    "    X = np.zeros((len(reviews), model.d))\n",
    "    for idx, review in enumerate(reviews):\n",
    "        X[idx, :] = get_review_embedding(model, review)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_features_matrix(model, sentences)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison models of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import clissifiers and necessary functions\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe from the json file\n",
    "df = pd.read_json(path_data_prepaired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels\n",
    "y = (df['overall'] > 3).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indices of rows which contain NaNs\n",
    "del_idx = np.argwhere(np.isnan(X))[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete rows with NaNs\n",
    "X = X[~np.isnan(X).any(axis=1)]\n",
    "y = y.drop(del_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try RF classifier out of the box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "cv_scores = cross_val_score(rf_clf, X_train, y_train, n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Accuracy score: {cv_scores.mean()} +/- {cv_scores.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model on the holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "print(f'Accuracy on holdout set: {accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': list(range(5, 51, 5)), 'max_depth': list(range(5, 100, 5)), \n",
    "         'min_samples_split': list(range(1, 11, 1))}\n",
    "\n",
    "clf = RandomizedSearchCV(RandomForestClassifier(), params, n_jobs=-1, \n",
    "                         cv=5, verbose=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost is very slow on mac ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbm_cls = XGBClassifier(random_state=42)\n",
    "cv_scores = cross_val_score(xgbm_cls, X_train, y_train, n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Accuracy score: {cv_scores.mean()} +/- {cv_scores.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.to_csv('../dataset/X_1.csv')\n",
    "y.to_csv('../dataset/y_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.to_csv('../dataset/X_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
